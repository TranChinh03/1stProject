{"version":3,"sources":["torch.ts"],"names":["torch","__torchlive__"],"mappings":";;;;;;;AAAA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AAEA;;AAIA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAYA;AACA;AACA;AACA;;AAUA;AACA;AACA;AACA;;AAmCA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAsBA;AACA;AACA;AACA;AACA;AAMA;AA6ZO,MAAMA,KAAY,GAAGC,aAAa,CAACD,KAAnC","sourcesContent":["/**\n * Copyright (c) Meta Platforms, Inc. and affiliates.\n *\n * This source code is licensed under the MIT license found in the\n * LICENSE file in the root directory of this source tree.\n *\n * @format\n */\n\n// Allows tensor data with arbitrary dimensions\ntype Item = ItemArray;\ninterface ItemArray extends Array<Item | number> {}\n\n/**\n * TypedArray type to allow index-based access to tensor data.\n *\n * {@link https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/TypedArray}\n *\n * The type should preferrably be `ArrayBufferView`. However, that type includes\n * `DataView`, which itself is not indexable.\n *\n * {@link https://developer.mozilla.org/en-US/docs/Web/API/ArrayBufferView}\n *\n * A valid TypeScript expression is as follows:\n *\n * ```\n * torch.rand([2, 3]).data[3];\n * ```\n */\ntype TypedArray =\n  | Int8Array\n  | Uint8Array\n  | Uint8ClampedArray\n  | Int16Array\n  | Uint16Array\n  | Int32Array\n  | Uint32Array\n  | Float32Array\n  | Float64Array;\n\n/**\n * The [[ModuleValue]] type is a convenient type representative of all possible\n * module output values.\n */\ntype ModuleValue =\n  | null\n  | string\n  | number\n  | boolean\n  | Tensor\n  | {[key: string]: ModuleValue}\n  | ModuleValue[];\n\n/**\n * The [[IValue]] type is a type representative of all supported\n * input types to [[Module]] forward function.\n */\ntype ModuleInputValue = string | number | boolean | Tensor;\n\nexport interface Module {\n  /**\n   * Module forward function.\n   *\n   * @param inputs Module inputs. Input could be of type [[ModuleInputValue]]\n   * @returns Module output, which is particular to the model and can be any of\n   * the [[ModuleValue]] union types.\n   */\n  forward<In extends ModuleInputValue, Out extends ModuleValue>(\n    ...inputs: In[]\n  ): Promise<Out>;\n  /**\n   * Synchronous module forward function.\n   *\n   * @param inputs Module inputs. Input could be of type [[ModuleInputValue]]\n   * @returns Module output, which is particular to the model and can be any of\n   * the [[ModuleValue]] union types.\n   */\n  forwardSync<In extends ModuleInputValue, Out extends ModuleValue>(\n    ...inputs: In[]\n  ): Out;\n}\n\ninterface JIT {\n  /**\n   * Loads a serialized mobile module.\n   *\n   * @param filePath Path to serialized mobile module.\n   */\n  _loadForMobile(filePath: string): Promise<Module>;\n}\n\n/**\n * A [[Dtype]] is an object that represents the data type of a [[Tensor]].\n *\n * :::note\n *\n * The `int64` (a.k.a. `long`) data types are not fully supported in React Native.\n * For now, use `.to({dtype: torch.int32})` to downcast before accessing such\n * methods as `.data()` and `.item()`.\n *\n * :::\n *\n * {@link https://pytorch.org/docs/1.11/tensor_attributes.html#torch-dtype}\n */\nexport type Dtype =\n  | 'double'\n  | 'float'\n  | 'float32'\n  | 'float64'\n  | 'int'\n  | 'int16'\n  | 'int32'\n  | 'int64' // Hermes doesn't support BigInt yet (https://github.com/facebook/hermes/issues/510)\n  | 'int8'\n  | 'long'\n  | 'short'\n  | 'uint8';\n\nexport type TensorOptions = {\n  /**\n   * The desired data type of a tensor.\n   */\n  dtype?: Dtype;\n};\n\n/**\n * A [[MemoryFormat]] is an object representing the memory format on which a [[Tensor]] is or will be allocated.\n *\n * {@link https://pytorch.org/docs/1.11/tensor_attributes.html#torch.torch.memory_format}\n */\nexport type MemoryFormat =\n  | 'channelsLast'\n  | 'contiguousFormat'\n  | 'preserveFormat';\n\n// Adopt the notion of a Scalar\nexport type Scalar = number;\n\nexport interface Tensor {\n  /**\n   * Computes the absolute value of each element in input.\n   *\n   * {@link https://pytorch.org/docs/1.11/generated/torch.Tensor.abs.html}\n   */\n  abs(): Tensor;\n  /**\n   * Add a scalar or tensor to this tensor.\n   *\n   * {@link https://pytorch.org/docs/1.11/generated/torch.Tensor.add.html}\n   *\n   * @param other Scalar or tensor to be added to each element in this tensor.\n   * @param options.alpha The multiplier for `other`. Default: `1`.\n   */\n  add(other: Scalar | Tensor, options?: {alpha?: Number}): Tensor;\n  /**\n   * Returns the indices of the maximum value of all elements in the input\n   * tensor.\n   *\n   * {@link https://pytorch.org/docs/1.11/generated/torch.Tensor.argmax.html}\n   *\n   * @param options argmax Options as keywords argument in pytorch\n   * @param options.dim The dimension to reduce. If `undefined`, the argmax of the flattened input is returned.\n   * @param options.keepdim Whether the output tensor has `dim` retained or not. Ignored if `dim` is `undefined`.\n   */\n  argmax(options?: {dim?: number; keepdim?: boolean}): Tensor;\n  /**\n   * Clamps all elements in input into the range `[ min, max ]`.\n   *\n   * If `min` is `undefined`, there is no lower bound. Or, if `max` is `undefined` there is no upper bound.\n   *\n   * {@link https://pytorch.org/docs/1.11/generated/torch.Tensor.clamp.html}\n   *\n   * @param min Lower-bound of the range to be clamped to\n   * @param max Upper-bound of the range to be clamped to\n   */\n  clamp(min: Scalar | Tensor, max?: Scalar | Tensor): Tensor;\n  /**\n   * Clamps all elements in input into the range `[ min, max ]`.\n   *\n   * If `min` is `undefined`, there is no lower bound. Or, if `max` is `undefined` there is no upper bound.\n   *\n   * {@link https://pytorch.org/docs/1.11/generated/torch.Tensor.clamp.html}\n   *\n   * @param options.min Lower-bound of the range to be clamped to\n   * @param options.max Upper-bound of the range to be clamped to\n   */\n  clamp(options: {min?: Scalar | Tensor; max?: Scalar | Tensor}): Tensor;\n  /**\n   * Returns a contiguous in memory tensor containing the same data as this\n   * tensor. If this tensor is already in the specified memory format, this\n   * function returns this tensor.\n   *\n   * @param options.memoryFormat The desired memory format of returned Tensor. Default: torch.contiguousFormat.\n   *\n   * {@link https://pytorch.org/docs/1.11/generated/torch.Tensor.contiguous.html}\n   */\n  contiguous(options?: {memoryFormat: MemoryFormat}): Tensor;\n  /**\n   * Returns the tensor data as `TypedArray` buffer.\n   *\n   * {@link https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/TypedArray}\n   *\n   * A valid TypeScript expression is as follows:\n   *\n   * ```typescript\n   * torch.rand([2, 3]).data()[3];\n   * ```\n   *\n   * :::note\n   *\n   * The function only exists in JavaScript.\n   *\n   * :::\n   *\n   * @experimental\n   */\n  data(): TypedArray;\n  /**\n   * Divides each element of the input input by the corresponding element of\n   * other.\n   *\n   * {@link https://pytorch.org/docs/1.11/generated/torch.Tensor.div.html}\n   *\n   * @param other Scalar or tensor that divides each element in this tensor.\n   * @param options.roundingMode Type of rounding applied to the result\n   */\n  div(\n    other: Scalar | Tensor,\n    options?: {roundingMode?: 'trunc' | 'floor'},\n  ): Tensor;\n  /**\n   * A dtype is an string that represents the data type of a torch.Tensor.\n   *\n   * {@link https://pytorch.org/docs/1.11/tensor_attributes.html}\n   */\n  dtype: Dtype;\n  /**\n   * Returns the value of this tensor as a `number`. This only works for\n   * tensors with one element.\n   *\n   * {@link https://pytorch.org/docs/1.11/generated/torch.Tensor.item.html}\n   */\n  item(): number;\n  /**\n   * Returns a tensor with the same data and number of elements as input, but\n   * with the specified shape.\n   *\n   * {@link https://pytorch.org/docs/1.11/generated/torch.Tensor.reshape.html}\n   *\n   * @param shape The new shape.\n   */\n  reshape(shape: number[]): Tensor;\n  /**\n   * Multiplies input by other scalar or tensor.\n   *\n   * {@link https://pytorch.org/docs/1.11/generated/torch.Tensor.mul.html}\n   *\n   * @param other Scalar or tensor multiplied with each element in this tensor.\n   */\n  mul(other: Scalar | Tensor): Tensor;\n  /**\n   * Returns a view of the original tensor input with its dimensions permuted.\n   *\n   * {@link https://pytorch.org/docs/1.11/generated/torch.Tensor.permute.html}\n   *\n   * @param dims The desired ordering of dimensions.\n   */\n  permute(dims: number[]): Tensor;\n  /**\n   * Returns the size of the tensor.\n   *\n   * {@link https://pytorch.org/docs/1.11/generated/torch.Tensor.size.html}\n   */\n  shape: number[];\n  /**\n   * Returns the size of the tensor.\n   *\n   * {@link https://pytorch.org/docs/1.11/generated/torch.Tensor.size.html}\n   */\n  size(): number[];\n  /**\n   * Applies a softmax function. It is applied to all slices along dim, and\n   * will re-scale them so that the elements lie in the range `[0, 1]` and sum\n   * to `1`.\n   *\n   * {@link https://pytorch.org/docs/1.11/generated/torch.nn.functional.softmax.html}\n   *\n   * @param dim A dimension along which softmax will be computed.\n   */\n  softmax(dim: number): Tensor;\n  /**\n   * Computes the square-root value of each element in input.\n   *\n   * {@link https://pytorch.org/docs/1.11/generated/torch.Tensor.sqrt.html}\n   */\n  sqrt(): Tensor;\n  /**\n   * Returns a tensor with all the dimensions of input of size 1 removed.\n   *\n   * {@link https://pytorch.org/docs/1.11/generated/torch.Tensor.squeeze.html}\n   *\n   * @param dim If given, the input will be squeezed only in this dimension.\n   */\n  squeeze(dim?: number): Tensor;\n  /**\n   * Returns the stride of the tensor.\n   *\n   * {@link https://pytorch.org/docs/1.11/generated/torch.Tensor.stride.html}\n   */\n  stride(): number[];\n  /**\n   * Returns the stride of the tensor.\n   *\n   * {@link https://pytorch.org/docs/1.11/generated/torch.Tensor.stride.html}\n   *\n   * @param dim The desired dimension in which stride is required.\n   */\n  stride(dim: number): number;\n  /**\n   * Subtracts other from input.\n   *\n   * {@link https://pytorch.org/docs/1.11/generated/torch.Tensor.sub.html}\n   *\n   * @param other The scalar or tensor to subtract from input.\n   * @param options.alpha The multiplier for `other`. Default: `1`.\n   */\n  sub(other: Scalar | Tensor, options?: {alpha?: Number}): Tensor;\n  /**\n   * Returns the sum of all elements in the input tensor.\n   *\n   * {@link https://pytorch.org/docs/1.11/generated/torch.Tensor.sum.html}\n   */\n  sum(): Tensor;\n  /**\n   * Returns the sum of each row of the input tensor in the given dimension dim.\n   * If dim is a list of dimensions, reduce over all of them.\n   *\n   * {@link https://pytorch.org/docs/1.11/generated/torch.Tensor.sum.html}\n   *\n   * @param dim The dimension or dimensions to reduce.\n   * @param options.keepdim Whether the output tensor has `dim` retained or not.\n   */\n  sum(dim: number | number[], options?: {keepdim?: boolean}): Tensor;\n  /**\n   * Performs Tensor conversion.\n   *\n   * {@link https://pytorch.org/docs/1.11/generated/torch.Tensor.to.html}\n   *\n   * @param options Tensor options.\n   */\n  to(options: TensorOptions): Tensor;\n  /**\n   * Returns the k largest elements of the given input tensor along a given\n   * dimension.\n   *\n   * {@link https://pytorch.org/docs/1.11/generated/torch.Tensor.topk.html}\n   *\n   * @param k The k in \"top-k\"\n   */\n  topk(k: number): [Tensor, Tensor];\n  /**\n   * Returns a new tensor with a dimension of size one inserted at the\n   * specified position.\n   *\n   * {@link https://pytorch.org/docs/1.11/generated/torch.Tensor.unsqueeze.html}\n   *\n   * @param dim The index at which to insert the singleton dimension.\n   */\n  unsqueeze(dim: number): Tensor;\n  /**\n   * Access tensor with index.\n   *\n   * ```typescript\n   * const tensor = torch.rand([2]);\n   * console.log(tensor.data, tensor[0].data);\n   * // [0.8339180946350098, 0.17733973264694214], [0.8339180946350098]\n   * ```\n   *\n   * {@link https://pytorch.org/cppdocs/notes/tensor_indexing.html}\n   */\n  [index: number]: Tensor;\n}\n\nexport interface Torch {\n  /**\n   * Returns a 1-D tensor of size `(end - 0) / 1` with values from the interval\n   * `[0, end)` taken with common difference step beginning from start.\n   *\n   * {@link https://pytorch.org/docs/1.11/generated/torch.arange.html}\n   *\n   * @param end The ending value for the set of points.\n   * @param options\n   */\n  arange(end: number, options?: TensorOptions): Tensor;\n  /**\n   * Returns a 1-D tensor of size `(end - start) / 1` with values from the\n   * interval `[start, end)` taken with common difference 1 beginning from\n   * `start`.\n   *\n   * {@link https://pytorch.org/docs/1.11/generated/torch.arange.html}\n   *\n   * @param start The starting value for the set of points.\n   * @param end The ending value for the set of points.\n   * @param options\n   */\n  arange(start: number, end: number, options?: TensorOptions): Tensor;\n  /**\n   * Returns a 1-D tensor of size `(end - start) / step` with values from the\n   * interval `[start, end)` taken with common difference `step` beginning from\n   * `start`.\n   *\n   * {@link https://pytorch.org/docs/1.11/generated/torch.arange.html}\n   *\n   * @param start The starting value for the set of points.\n   * @param end The ending value for the set of points.\n   * @param step The gap between each pair of adjacent points.\n   * @param options\n   */\n  arange(\n    start: number,\n    end: number,\n    step: number,\n    options?: TensorOptions,\n  ): Tensor;\n  /**\n   * Returns a tensor filled with uninitialized data. The shape of the tensor\n   * is defined by the variable argument size.\n   *\n   * {@link https://pytorch.org/docs/1.11/generated/torch.empty.html}\n   *\n   * @param size A sequence of integers defining the shape of the output\n   * tensor.\n   */\n  empty(size: number[], options?: TensorOptions): Tensor;\n  /**\n   * Returns a tensor filled with ones on the diagonal, and zeroes elsewhere.\n   * The shape of the tensor is defined by the arguments n and m.\n   *\n   * {@link https://pytorch.org/docs/1.11/generated/torch.eye.html}\n   *\n   * @param n An integer defining the number of rows in the result.\n   * @param m An integer defining the number of columns in the result. Optional, defaults to n.\n   */\n  eye(n: number, m?: number, options?: TensorOptions): Tensor;\n  /**\n   * Exposes the given data as a Tensor without taking ownership of the\n   * original data.\n   *\n   * :::note\n   *\n   * The function exists in JavaScript and C++ (torch::from_blob).\n   *\n   * :::\n   *\n   * @param blob The blob holding the data.\n   * @param sizes Should specify the shape of the tensor, strides the stride\n   * @param options Tensor options\n   * in each dimension.\n   */\n  fromBlob(blob: any, sizes?: number[], options?: TensorOptions): Tensor;\n  /**\n   * Returns a tensor filled with the scalar value 1, with the shape defined\n   * by the argument `size`.\n   *\n   * {@link https://pytorch.org/docs/1.11/generated/torch.ones.html}\n   *\n   * @param size A sequence of integers defining the shape of the output tensor.\n   * @param options Tensor options.\n   */\n  ones(size: number[], options?: TensorOptions): Tensor;\n  /**\n   * Returns a tensor filled with random numbers from a uniform distribution on\n   * the interval `[0, 1)`.\n   *\n   * @param size A sequence of integers defining the shape of the output tensor.\n   * @param options Tensor options.\n   */\n  rand(size: number[], options?: TensorOptions): Tensor;\n  /**\n   * Returns a tensor filled with random integers generated uniformly between\n   * `0` (inclusive) and `high` (exclusive).\n   *\n   * {@link https://pytorch.org/docs/1.11/generated/torch.randint.html}\n   *\n   * @param high One above the highest integer to be drawn from the distribution.\n   * @param size A tuple defining the shape of the output tensor.\n   */\n  randint(high: number, size: number[]): Tensor;\n  /**\n   * Returns a tensor filled with random integers generated uniformly between\n   * `low` (inclusive) and `high` (exclusive).\n   *\n   * {@link https://pytorch.org/docs/1.11/generated/torch.randint.html}\n   *\n   * @param low Lowest integer to be drawn from the distribution.\n   * @param high One above the highest integer to be drawn from the distribution.\n   * @param size A tuple defining the shape of the output tensor.\n   */\n  randint(low: number, high: number, size: number[]): Tensor;\n  /**\n   * Constructs a tensor with no autograd history.\n   *\n   * @param data Tensor data as multi-dimensional array.\n   * @param options Tensor options.\n   */\n  tensor(data: Scalar | ItemArray, options?: TensorOptions): Tensor;\n  /**\n   * Returns a tensor filled with the scalar value 0, with the shape defined\n   * by the argument `size`.\n   *\n   * {@link https://pytorch.org/docs/1.11/generated/torch.zeros.html}\n   *\n   * @param size A sequence of integers defining the shape of the output tensor.\n   * @param options Tensor options.\n   */\n  zeros(size: number[], options?: TensorOptions): Tensor;\n\n  /**\n   * JIT module\n   */\n  jit: JIT;\n\n  // Tensor Data Type\n  double: 'double';\n  float: 'float';\n  float32: 'float32';\n  float64: 'float64';\n  int: 'int';\n  int16: 'int16';\n  int32: 'int32';\n  int64: 'int64';\n  int8: 'int8';\n  long: 'long';\n  short: 'short';\n  uint8: 'uint8';\n\n  // Memory Format\n  channelsLast: 'channelsLast';\n  contiguousFormat: 'contiguousFormat';\n  preserveFormat: 'preserveFormat';\n}\n\ntype Torchlive = {\n  torch: Torch;\n};\n\ndeclare const __torchlive__: Torchlive;\n\nexport const torch: Torch = __torchlive__.torch;\n"]}